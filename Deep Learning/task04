### 注意力机制
注意力机制是本质上是为了模仿人类观察物品的方式。


注意力机制其实包含两个部分
1. 注意力机制需要决定整段输入的哪个部分需要更加关注
2. 从关键的部分进行特征提取，得到重要的信息


### Seq2seq模型
Seq2Seq模型是输出的长度不确定时采用的模型，这种情况一般是在机器翻译的任务中出现

Seq2Seq结构：
利用两个RNN，一个RNN作为encoder，另一个RNN作为decoder。
encoder： 负责将输入序列压缩成指定长度的向量
decoder： 负责根据语义向量生成指定的序列

